# More ANE Transformers

Hardware-accelerated transformers on your Mac via CoreML. (Yes, that includes LLMs like GPT.)

## Try It
Generate text with a base gpt2 model like this:
```
‚ùØ ./setup.sh && source env/bin/activate
‚ùØ python3 convert.py
‚ùØ python3 generate.py
Loading model from path gpt2.mlpackage using ComputeUnit.ALL...
Loaded model in 11.959s.

[Prompt] Before boarding your rocket to Mars, remember to pack these items on board:
...
```

That model is tiny‚Äîsometimes the results are a bit nonsensical. You can run larger models for better results:
|Model|Parameters|Size|Download|
|--|--|--|--|
|gpt2|124M|250MB|[link](https://github.com/smpanaro/more-ane-transformers/releases/tag/v0-2023-April-02)|
|gpt2-medium|350M|700MB|[link](https://github.com/smpanaro/more-ane-transformers/releases/tag/v0-2023-April-02)|
|gpt2-large|774M|1.5GB|[link](https://github.com/smpanaro/more-ane-transformers/releases/tag/v0-2023-April-02)|
|gpt2-xl|1558M|3GB|[link](https://github.com/smpanaro/more-ane-transformers/releases/tag/v0-2023-April-02)|

You can also see [evals/QUALITY.md](evals/QUALITY.md) for some example generations.

## Why CoreML?
Apple Silicon Macs have custom hardware built for machine learning (‚ú®the neural engine). Its fast and power efficient but the only way to use it is through CoreML. This repo makes it easy.

## Is it fast?
The gpt2-xl (1.5B) model runs *~1.5 words/sec* running purely on Neural Engine. *~2.5 words/sec* if you have a new Mac with a fast GPU. Smaller models are faster (from a little to a lot -- every model is ~2x faster than the next largest).

See [evals/SPEED.md](evals/SPEED.md) for device benchmarks.

<img width="1074" alt="Xcode CoreML Performance test for gpt2-xl" src="https://user-images.githubusercontent.com/2950214/229385079-1ac5ee4c-3531-4e1d-bed3-cb870eee9158.png">
<sub>note this is prior to a 30% speedup (to 445ms), important part is how purple the bar is :)</sub>


## What about iOS?
Smaller models (gpt2, maybe gpt2-medium) should run but larger models require too much memory. Quantization doesn‚Äôt help because CoreML uses float32 or float16 when running. ü§û Apple changes this soon.

## Contribute
PRs welcome! New models ‚òëÔ∏è Fixing bugs ‚òëÔ∏è Speedups ‚òëÔ∏è

## Thanks
This project really just stitches together previously open-sourced tools. Thanks y‚Äôall.
- [coremltools](https://github.com/apple/coremltools) - to make CoreML models
- [ane-ml-transformers](https://github.com/apple/ml-ane-transformers) - to make CoreML models go fast
- [nanoGPT](https://github.com/karpathy/nanoGPT) - for a hackable GPT2 implementation
- [huggingface](https://huggingface.co) - for weights + tokenizers
- [ANE-Optimized-Whisper-OpenAI](https://github.com/RobertRiachi/ANE-Optimized-Whisper-OpenAI) - for splitting the embedding layer
- [whisper_ane](https://github.com/Synopsis/whisper_ane) - for another ane example
- [Netron](https://netron.app) - for clutch visualization
- [ChatGPT](http://chat.openai.com) - for bouncing ideas
